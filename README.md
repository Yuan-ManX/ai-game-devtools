# Game-AI-Toolkit

Here we will keep track of the Game AI Development Toolkit, including programming, animation, effects, modeling, audio, music and more.

## Contents

| Source                                                             | Description                                                                                                                               |  Game Engine  |   Type   |
| :----------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- | :-----------: | :-------: |
| [AICommand](https://github.com/keijiro/AICommand)                     | ChatGPT integration with Unity Editor.                                                                                                    |     Unity     |   Tool   |
| [Sanity AI Engine](https://github.com/tosos/SanityEngine)             | Sanity AI Engine for the Unity Game Development Tool.                                                                                     |     Unity     |   Tool   |
| [UnrealGPT](https://github.com/TREE-Ind/UnrealGPT)                    | A collection of Unreal Engine 5 Editor Utility widgets powered by GPT3/4.                                                                 | Unreal Engine |   Tool   |
| [AI Shader](https://github.com/keijiro/AIShader)                      | ChatGPT-powered shader generator for Unity.                                                                                               |     Unity     |  Shader  |
| [DALL·E 2](https://openai.com/product/dall-e-2)                      | DALL·E 2 is an AI system that can create realistic images and art from a description in natural language.                                |              |   Image   |
| [Stable Diffusion](https://github.com/CompVis/stable-diffusion)       | A latent text-to-image diffusion model.                                                                                                   |              |   Image   |
| [Stable Diffusion web UI](https://github.com/Sygil-Dev/sygil-webui)   | Web-based UI for Stable Diffusion.                                                                                                        |              |   Image   |
| [Disco Diffusion](https://github.com/alembics/disco-diffusion)        | A frankensteinian amalgamation of notebooks, models and techniques for the generation of AI Art and Animations.                           |              |   Image   |
| [ControlNet](https://github.com/lllyasviel/ControlNet)                | ControlNet is a neural network structure to control diffusion models by adding extra conditions.                                          |              |   Image   |
| [Blender-ControlNet](https://github.com/coolzilj/Blender-ControlNet)  | Using ControlNet right in Blender.                                                                                                        |              |   Image   |
| [Midjourney](https://www.midjourney.com/)                             | Midjourney is an independent research lab exploring new mediums of thought and expanding the imaginative powers of the human species.     |              |   Image   |
| [Lexica](https://lexica.art/)                                         | A Stable Diffusion prompts search engine.                                                                                                 |              |   Image   |
| [Photoroom](https://www.photoroom.com/backgrounds)                    | AI Background Generator.                                                                                                                  |              |   Image   |
| [Polycam](https://poly.cam/material-generator)                        | Create your own 3D textures just by typing.                                                                                               |              |  Texture  |
| [Gen-2](https://research.runwayml.com/gen2)                           | A multi-modal AI system that can generate novel videos with text, images, or video clips.                                                 |              |   Video   |
| [Sloyd](https://www.sloyd.ai/)                                        | 3D modelling has never been easier.                                                                                                       |              |   Model   |
| [Point·E](https://github.com/openai/point-e)                         | Point cloud diffusion for 3D model synthesis.                                                                                             |              |   Model   |
| [Notebook.ai](https://github.com/indentlabs/notebook)                 | Notebook.ai is a set of tools for writers, game designers, and roleplayers to create magnificent universes – and everything within them. |              |  Writer  |
| [NovelAI](https://novelai.net/)                                       | Driven by AI, painlessly construct unique stories, thrilling tales, seductive romances, or just fool around.                              |              |  Writer  |
| [CodeGeeX](https://github.com/THUDM/CodeGeeX)                         | An Open Multilingual Code Generation Model.                                                                                               |              |   Code   |
| [Cursor](https://www.cursor.so/)                                      | Write, edit, and chat about your code with GPT-4 in a new type of editor.                                                                 |              |   Code   |
| [GameAISDK](https://github.com/Tencent/GameAISDK)                     | Image-based game AI automation framework.                                                                                                 |              | Framework |
| [behaviac](https://github.com/Tencent/behaviac)                       | Behaviac is a framework of the game AI development.                                                                                       |              | Framework |
| [LogicGamesSolver](https://github.com/fabridigua/LogicGamesSolver)    | A Python tool to solve logic games with AI, Deep Learning and Computer Vision.                                                            |              |   Tool   |
| [ArchiSound](https://github.com/archinetai/audio-diffusion-pytorch)   | Audio generation using diffusion models, in PyTorch.                                                                                      |              |   Audio   |
| [Make-An-Audio](https://text-to-audio.github.io/)                     | Text-To-Audio Generation with Prompt-Enhanced Diffusion Models.                                                                           |              |   Audio   |
| [AudioLDM](https://audioldm.github.io/)                               | Text-to-Audio Generation with Latent Diffusion Models.                                                                                    |              |   Audio   |
| [MusicLM](https://google-research.github.io/seanet/musiclm/examples/) | Generating Music From Text.                                                                                                               |              |   Music   |
| [Riffusion App](https://github.com/riffusion/riffusion-app)           | Riffusion is an app for real-time music generation with stable diffusion.                                                                 |              |   Music   |
| [Jukebox](https://github.com/openai/jukebox)                          | A Generative Model for Music.                                                                                                             |              |   Music   |
| [so-vits-svc](https://github.com/svc-develop-team/so-vits-svc)        | SoftVC VITS Singing Voice Conversion.                                                                                                     |              |   Voice   |
| [VALL-E](https://valle-demo.github.io/)                               | Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers.                                                                   |              |  Speech  |
| [VALL-E X](https://vallex-demo.github.io/)                            | Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling                                                 |              |  Speech  |
